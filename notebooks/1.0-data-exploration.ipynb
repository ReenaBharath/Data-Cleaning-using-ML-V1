{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Exploration and Initial Analysis\n",
    "\n",
    "This notebook performs initial exploration of our dataset and analyzes the quality of different columns before implementing the cleaning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/raw/input_dataset.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Column Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_text_column(texts):\n",
    "    \"\"\"Analyze text column for various metrics\"\"\"\n",
    "    metrics = {\n",
    "        'total_rows': len(texts),\n",
    "        'null_count': texts.isnull().sum(),\n",
    "        'empty_count': texts.str.strip().eq('').sum(),\n",
    "        'unique_count': texts.nunique(),\n",
    "        'avg_length': texts.str.len().mean(),\n",
    "        'min_length': texts.str.len().min(),\n",
    "        'max_length': texts.str.len().max(),\n",
    "    }\n",
    "    \n",
    "    # Calculate length distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    texts.str.len().hist(bins=50)\n",
    "    plt.title('Text Length Distribution')\n",
    "    plt.xlabel('Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.Series(metrics)\n",
    "\n",
    "# Analyze text column\n",
    "text_metrics = analyze_text_column(df['text'])\n",
    "print(\"Text Column Metrics:\")\n",
    "print(text_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_text_issues(texts):\n",
    "    \"\"\"Detect various issues in text data\"\"\"\n",
    "    issues = {\n",
    "        'urls': [],\n",
    "        'non_english': [],\n",
    "        'short_text': [],\n",
    "        'special_chars': [],\n",
    "        'rt_prefix': []\n",
    "    }\n",
    "    \n",
    "    for idx, text in enumerate(texts):\n",
    "        if pd.isna(text):\n",
    "            continue\n",
    "            \n",
    "        # Check for URLs\n",
    "        if re.search(r'http\\S+|www\\S+|https\\S+', text):\n",
    "            issues['urls'].append(idx)\n",
    "        \n",
    "        # Check language\n",
    "        try:\n",
    "            if detect(text) != 'en':\n",
    "                issues['non_english'].append(idx)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Check length\n",
    "        if len(text.split()) < 3:\n",
    "            issues['short_text'].append(idx)\n",
    "        \n",
    "        # Check special characters\n",
    "        if re.search(r'[^\\w\\s.,!?]', text):\n",
    "            issues['special_chars'].append(idx)\n",
    "        \n",
    "        # Check RT prefix\n",
    "        if text.startswith('RT') or text.startswith('rt'):\n",
    "            issues['rt_prefix'].append(idx)\n",
    "    \n",
    "    return {k: len(v) for k, v in issues.items()}\n",
    "\n",
    "# Analyze text issues\n",
    "text_issues = detect_text_issues(df['text'])\n",
    "print(\"\\nText Issues Found:\")\n",
    "for issue, count in text_issues.items():\n",
    "    print(f\"{issue}: {count} instances ({count/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hashtag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_hashtags(hashtags):\n",
    "    \"\"\"Analyze hashtag patterns and issues\"\"\"\n",
    "    # Split hashtags into individual tags\n",
    "    all_tags = []\n",
    "    for tags in hashtags.dropna():\n",
    "        if isinstance(tags, str):\n",
    "            all_tags.extend(tags.split())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    tag_counts = Counter(all_tags)\n",
    "    \n",
    "    metrics = {\n",
    "        'total_hashtags': len(all_tags),\n",
    "        'unique_hashtags': len(tag_counts),\n",
    "        'avg_per_row': len(all_tags) / len(hashtags),\n",
    "        'rows_with_tags': hashtags.notna().sum(),\n",
    "    }\n",
    "    \n",
    "    # Plot top hashtags\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    pd.Series(dict(tag_counts.most_common(20))).plot(kind='bar')\n",
    "    plt.title('Top 20 Hashtags')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.Series(metrics)\n",
    "\n",
    "# Analyze hashtags\n",
    "hashtag_metrics = analyze_hashtags(df['hashtags'])\n",
    "print(\"\\nHashtag Metrics:\")\n",
    "print(hashtag_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Country Code Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_country_codes(codes):\n",
    "    \"\"\"Analyze country code distribution and validity\"\"\"\n",
    "    # Valid country codes (example list)\n",
    "    valid_codes = {'US', 'UK', 'IN', 'CN', 'JP', 'DE', 'FR', 'IT', 'BR', 'CA'}\n",
    "    \n",
    "    metrics = {\n",
    "        'total_rows': len(codes),\n",
    "        'null_count': codes.isnull().sum(),\n",
    "        'unique_codes': codes.nunique(),\n",
    "        'invalid_codes': sum(1 for code in codes.dropna() if code.upper() not in valid_codes)\n",
    "    }\n",
    "    \n",
    "    # Plot code distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    codes.value_counts().head(20).plot(kind='bar')\n",
    "    plt.title('Country Code Distribution (Top 20)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.Series(metrics)\n",
    "\n",
    "# Analyze country codes\n",
    "country_metrics = analyze_country_codes(df['country_code'])\n",
    "print(\"\\nCountry Code Metrics:\")\n",
    "print(country_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Development Status Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_development_status(status):\n",
    "    \"\"\"Analyze development status distribution and standardization needs\"\"\"\n",
    "    # Standardize status for analysis\n",
    "    status = status.str.lower()\n",
    "    \n",
    "    metrics = {\n",
    "        'total_rows': len(status),\n",
    "        'null_count': status.isnull().sum(),\n",
    "        'unique_values': status.nunique(),\n",
    "        'developed_count': sum(1 for s in status.dropna() if 'developed' in str(s)),\n",
    "        'developing_count': sum(1 for s in status.dropna() if 'developing' in str(s)),\n",
    "        'unclear_count': sum(1 for s in status.dropna() if 'developed' not in str(s) and 'developing' not in str(s))\n",
    "    }\n",
    "    \n",
    "    # Plot status distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    status.value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "    plt.title('Development Status Distribution')\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.Series(metrics)\n",
    "\n",
    "# Analyze development status\n",
    "status_metrics = analyze_development_status(df['development_status'])\n",
    "print(\"\\nDevelopment Status Metrics:\")\n",
    "print(status_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Column Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze relationships between columns\n",
    "def analyze_cross_columns(df):\n",
    "    \"\"\"Analyze relationships between different columns\"\"\"\n",
    "    # Text length by country\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='country_code', y=df['text'].str.len(), data=df)\n",
    "    plt.title('Text Length Distribution by Country')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Hashtag count by development status\n",
    "    df['hashtag_count'] = df['hashtags'].fillna('').str.split().str.len()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='development_status', y='hashtag_count', data=df)\n",
    "    plt.title('Hashtag Count by Development Status')\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation matrix\n",
    "    correlation_data = pd.DataFrame({\n",
    "        'text_length': df['text'].str.len(),\n",
    "        'hashtag_count': df['hashtag_count'],\n",
    "        'is_developed': (df['development_status'].str.lower().str.contains('developed')).astype(int)\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_data.corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Perform cross-column analysis\n",
    "analyze_cross_columns(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}
