{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for Data Cleaning Pipeline\n",
    "\n",
    "This notebook covers the training and fine-tuning of models used in our data cleaning pipeline. We'll focus on:\n",
    "1. Loading and preparing the data\n",
    "2. Setting up the models\n",
    "3. Training the development status classifier\n",
    "4. Model evaluation and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    logger.info(\"Using GPU for training\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") \n",
    "    logger.info(\"Using CPU for training\")\n",
    "\n",
    "# Ensure required directories exist\n",
    "Path(\"../models/cache\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "def load_config():\n",
    "    try:\n",
    "        config_path = Path('../configs/model_config.yaml')\n",
    "        if not config_path.exists():\n",
    "            raise FileNotFoundError(f\"Config file not found at {config_path}\")\n",
    "            \n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            \n",
    "        # Validate required config sections\n",
    "        required_sections = ['model_params', 'optimization', 'checkpoint', \n",
    "                           'logging', 'evaluation', 'early_stopping']\n",
    "        for section in required_sections:\n",
    "            if section not in config:\n",
    "                raise KeyError(f\"Missing required config section: {section}\")\n",
    "                \n",
    "        # Validate model params\n",
    "        model_params = config['model_params']\n",
    "        if not isinstance(model_params.get('device'), str):\n",
    "            raise ValueError(\"device must be a string ('cuda' or 'cpu')\")\n",
    "        if not isinstance(model_params.get('batch_size'), int):\n",
    "            raise ValueError(\"batch_size must be an integer\")\n",
    "            \n",
    "        return config\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading config: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    config = load_config()\n",
    "    logger.info(\"Configuration loaded successfully!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load configuration: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load and prepare the dataset for model training\"\"\"\n",
    "    try:\n",
    "        # Validate file path\n",
    "        if not Path(file_path).exists():\n",
    "            raise FileNotFoundError(f\"Data file not found at {file_path}\")\n",
    "            \n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_cols = ['text', 'hashtags', 'place_country_code', 'Developed / Developing']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Basic preprocessing\n",
    "        df['text'] = df['text'].fillna('').astype(str)\n",
    "        df['hashtags'] = df['hashtags'].fillna('').astype(str)\n",
    "        df['place_country_code'] = df['place_country_code'].fillna('UNK')  # Match config default\n",
    "        \n",
    "        # Validate development status values\n",
    "        df['development_status'] = df['Developed / Developing'].str.title()\n",
    "        valid_statuses = ['Developed', 'Developing']\n",
    "        invalid_statuses = df[~df['development_status'].isin(valid_statuses)]['development_status'].unique()\n",
    "        if len(invalid_statuses) > 0:\n",
    "            logger.warning(f\"Found invalid development statuses: {invalid_statuses}\")\n",
    "            df['development_status'] = df['development_status'].map(\n",
    "                lambda x: x if x in valid_statuses else None\n",
    "            )\n",
    "        \n",
    "        # Create binary labels for development status\n",
    "        df['label'] = df['development_status'].map({\n",
    "            'Developed': 1,\n",
    "            'Developing': 0\n",
    "        })\n",
    "        \n",
    "        # Drop rows with invalid labels\n",
    "        df = df.dropna(subset=['label'])\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No valid records remaining after preprocessing\")\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading and preparing data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    df = load_and_prepare_data('../data/raw/zero_waste.csv')\n",
    "    logger.info(f\"Loaded {len(df)} records\")\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    print(\"\\nSample data:\")\n",
    "    display(df.head())\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load and prepare data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config):\n",
    "        \"\"\"Initialize the model trainer with configuration\"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(config['model_params']['device'])\n",
    "        self.setup_models()\n",
    "        \n",
    "    def setup_models(self):\n",
    "        \"\"\"Initialize models and tokenizers\"\"\"\n",
    "        try:\n",
    "            # Development status model\n",
    "            model_config = self.config['model_params']['development_status']\n",
    "            \n",
    "            # Initialize tokenizer\n",
    "            self.dev_status_tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_config['model_name'],\n",
    "                cache_dir=model_config['cache_dir'],\n",
    "                use_fast=True  # Use fast tokenizer for better performance\n",
    "            )\n",
    "            \n",
    "            # Initialize model\n",
    "            self.dev_status_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_config['model_name'],\n",
    "                num_labels=model_config['num_labels'],\n",
    "                cache_dir=model_config['cache_dir'],\n",
    "                problem_type=\"single_label_classification\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            logger.info(\"Models initialized successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing models: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    def prepare_dataset(self, df, text_col, label_col):\n",
    "        \"\"\"Prepare dataset for training\"\"\"\n",
    "        try:\n",
    "            # Validate inputs\n",
    "            if text_col not in df.columns or label_col not in df.columns:\n",
    "                raise ValueError(f\"Required columns {text_col} and/or {label_col} not found in dataframe\")\n",
    "                \n",
    "            # Create features\n",
    "            features = [{\n",
    "                'text': str(row[text_col]),\n",
    "                'label': int(row[label_col])\n",
    "            } for _, row in df.iterrows()]\n",
    "            \n",
    "            # Convert to Dataset format\n",
    "            dataset = Dataset.from_list(features)\n",
    "            \n",
    "            # Tokenize function\n",
    "            def tokenize_function(examples):\n",
    "                return self.dev_status_tokenizer(\n",
    "                    examples['text'],\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    max_length=self.config['model_params']['max_length'],\n",
    "                    return_tensors=None  # Return as lists\n",
    "                )\n",
    "            \n",
    "            # Tokenize dataset\n",
    "            tokenized_dataset = dataset.map(\n",
    "                tokenize_function,\n",
    "                batched=True,\n",
    "                remove_columns=dataset.column_names,\n",
    "                desc=\"Tokenizing dataset\"\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Dataset prepared successfully with {len(tokenized_dataset)} samples\")\n",
    "            return tokenized_dataset\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error preparing dataset: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "try:\n",
    "    # Initialize trainer\n",
    "    trainer = ModelTrainer(config)\n",
    "    print(\"Model trainer initialized successfully!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize model trainer: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data with stratification to maintain class distribution\n",
    "train_df, eval_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2, \n",
    "    random_state=config['model_params']['seed'],\n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "# Verify split sizes\n",
    "logger.info(f\"Training set size: {len(train_df)}\")\n",
    "logger.info(f\"Evaluation set size: {len(eval_df)}\")\n",
    "\n",
    "try:\n",
    "    # Prepare datasets\n",
    "    train_dataset = trainer.prepare_dataset(train_df, 'text', 'label')\n",
    "    eval_dataset = trainer.prepare_dataset(eval_df, 'text', 'label')\n",
    "\n",
    "    # Log dataset sizes\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Evaluation samples: {len(eval_dataset)}\")\n",
    "\n",
    "    # Validate datasets\n",
    "    assert len(train_dataset) > 0, \"Training dataset is empty\"\n",
    "    assert len(eval_dataset) > 0, \"Evaluation dataset is empty\"\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error preparing datasets: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_training(config, train_dataset, eval_dataset):\n",
    "    \"\"\"Setup training arguments and trainer for development status classification\"\"\"\n",
    "    try:\n",
    "        # Import required classes\n",
    "        from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "        # Setup training arguments with values from config\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"../models/dev_status_model\",\n",
    "            num_train_epochs=config['model_params']['num_epochs'],\n",
    "            per_device_train_batch_size=config['model_params']['batch_size'],\n",
    "            per_device_eval_batch_size=config['model_params']['batch_size'],\n",
    "            learning_rate=config['model_params']['learning_rate'],\n",
    "            warmup_steps=config['model_params']['warmup_steps'],\n",
    "            weight_decay=config['model_params']['weight_decay'],\n",
    "            logging_dir=config['logging']['logging_dir'],\n",
    "            logging_steps=config['logging']['logging_steps'],\n",
    "            evaluation_strategy=config['evaluation']['eval_strategy'],\n",
    "            save_strategy=config['checkpoint']['save_strategy'],\n",
    "            load_best_model_at_end=config['checkpoint']['load_best_model_at_end'],\n",
    "            metric_for_best_model=config['evaluation']['metric_for_best_model'],\n",
    "            greater_is_better=config['evaluation']['greater_is_better'],\n",
    "            gradient_accumulation_steps=config['model_params']['gradient_accumulation_steps'],\n",
    "            fp16=config['optimization']['use_mixed_precision'],\n",
    "            gradient_checkpointing=config['optimization']['use_gradient_checkpointing'],\n",
    "            max_grad_norm=config['optimization']['max_grad_norm']\n",
    "        )\n",
    "        \n",
    "        # Setup trainer with model and datasets\n",
    "        model_trainer = Trainer(\n",
    "            model=model,  # Use the model instance passed from outside\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            tokenizer=tokenizer,  # Use the tokenizer instance passed from outside\n",
    "            data_collator=DataCollatorWithPadding(tokenizer)\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Training setup completed successfully\")\n",
    "        return model_trainer\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in training setup: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Setup training with error handling\n",
    "try:\n",
    "    model_trainer = setup_training(config, train_dataset, eval_dataset)\n",
    "    logger.info(\"Training setup completed!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to setup training: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Analysis and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_distribution(df):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of labels and data characteristics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'text' and 'development_status' columns\n",
    "        \n",
    "    Returns:\n",
    "        None - Displays plots and prints statistics\n",
    "    \"\"\"\n",
    "    # Import required libraries if not already imported\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Validate input data\n",
    "    required_columns = ['text', 'development_status'] \n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(\"DataFrame must contain 'text' and 'development_status' columns\")\n",
    "    \n",
    "    # Create figure for label distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x='development_status')\n",
    "    plt.title('Distribution of Development Status Labels')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate text lengths\n",
    "    df['text_length'] = df['text'].astype(str).str.len()\n",
    "    \n",
    "    # Create figure for text length distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=df, x='text_length', bins=50)\n",
    "    plt.title('Distribution of Text Length')\n",
    "    plt.xlabel('Number of Characters')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nDevelopment Status Distribution:\")\n",
    "    status_dist = df['development_status'].value_counts(normalize=True)\n",
    "    for status, pct in status_dist.items():\n",
    "        print(f\"{status}: {pct:.2%}\")\n",
    "    \n",
    "    print(\"\\nText Length Statistics:\")\n",
    "    length_stats = df['text_length'].describe()\n",
    "    print(f\"Mean length: {length_stats['mean']:.1f} characters\")\n",
    "    print(f\"Median length: {length_stats['50%']:.1f} characters\")\n",
    "    print(f\"Min length: {length_stats['min']:.0f} characters\")\n",
    "    print(f\"Max length: {length_stats['max']:.0f} characters\")\n",
    "\n",
    "# Analyze data\n",
    "try:\n",
    "    analyze_data_distribution(df)\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing data distribution: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
