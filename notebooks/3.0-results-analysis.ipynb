{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Results Analysis\n",
    "\n",
    "This notebook analyzes the results of our ML-based data cleaning pipeline, comparing the original and cleaned datasets to evaluate the effectiveness of our cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud\n",
    "from scipy import stats\n",
    "import yaml\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the original and cleaned datasets\n",
    "original_df = pd.read_csv('../data/raw/input_dataset.csv')\n",
    "cleaned_df = pd.read_csv('../data/processed/cleaned_dataset.csv')\n",
    "\n",
    "# Load configuration\n",
    "with open('../configs/cleaning_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Statistics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_basic_stats(original_df, cleaned_df):\n",
    "    stats_dict = {\n",
    "        'Metric': [\n",
    "            'Total Records',\n",
    "            'Records Removed',\n",
    "            'Removal Rate (%)',\n",
    "            'Average Text Length',\n",
    "            'Median Text Length',\n",
    "            'Average Hashtags per Record',\n",
    "            'Unique Country Codes',\n",
    "            'Missing Values (Total)'\n",
    "        ],\n",
    "        'Original': [\n",
    "            len(original_df),\n",
    "            0,\n",
    "            0,\n",
    "            original_df['text'].str.len().mean(),\n",
    "            original_df['text'].str.len().median(),\n",
    "            original_df['hashtags'].str.count('#').mean(),\n",
    "            original_df['country_code'].nunique(),\n",
    "            original_df.isnull().sum().sum()\n",
    "        ],\n",
    "        'Cleaned': [\n",
    "            len(cleaned_df),\n",
    "            len(original_df) - len(cleaned_df),\n",
    "            ((len(original_df) - len(cleaned_df)) / len(original_df) * 100),\n",
    "            cleaned_df['text'].str.len().mean(),\n",
    "            cleaned_df['text'].str.len().median(),\n",
    "            cleaned_df['hashtags'].str.count('#').mean(),\n",
    "            cleaned_df['country_code'].nunique(),\n",
    "            cleaned_df.isnull().sum().sum()\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(stats_dict).round(2)\n",
    "\n",
    "basic_stats = calculate_basic_stats(original_df, cleaned_df)\n",
    "basic_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_text_quality(df, column='text'):\n",
    "    \"\"\"Analyze text quality metrics\"\"\"\n",
    "    metrics = {\n",
    "        'Total Words': df[column].str.split().str.len().sum(),\n",
    "        'Unique Words': len(set(' '.join(df[column].dropna()).split())),\n",
    "        'Average Words per Text': df[column].str.split().str.len().mean(),\n",
    "        'Text Length Std Dev': df[column].str.len().std(),\n",
    "        'Empty Texts': df[column].isna().sum(),\n",
    "        'Short Texts (<10 chars)': (df[column].str.len() < 10).sum()\n",
    "    }\n",
    "    return pd.Series(metrics)\n",
    "\n",
    "# Compare text quality\n",
    "original_quality = analyze_text_quality(original_df)\n",
    "cleaned_quality = analyze_text_quality(cleaned_df)\n",
    "\n",
    "quality_comparison = pd.DataFrame({\n",
    "    'Original': original_quality,\n",
    "    'Cleaned': cleaned_quality,\n",
    "    'Change (%)': ((cleaned_quality - original_quality) / original_quality * 100).round(2)\n",
    "})\n",
    "\n",
    "quality_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization of Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_text_length_distribution(original_df, cleaned_df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot original distribution\n",
    "    sns.histplot(data=original_df, x=original_df['text'].str.len(),\n",
    "                label='Original', alpha=0.5, bins=50)\n",
    "    \n",
    "    # Plot cleaned distribution\n",
    "    sns.histplot(data=cleaned_df, x=cleaned_df['text'].str.len(),\n",
    "                label='Cleaned', alpha=0.5, bins=50)\n",
    "    \n",
    "    plt.title('Text Length Distribution Before and After Cleaning')\n",
    "    plt.xlabel('Text Length (characters)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_text_length_distribution(original_df, cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_country_distribution(original_df, cleaned_df):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add original distribution\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=original_df['country_code'].value_counts().index,\n",
    "        y=original_df['country_code'].value_counts().values,\n",
    "        name='Original',\n",
    "        marker_color='lightblue'\n",
    "    ))\n",
    "    \n",
    "    # Add cleaned distribution\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cleaned_df['country_code'].value_counts().index,\n",
    "        y=cleaned_df['country_code'].value_counts().values,\n",
    "        name='Cleaned',\n",
    "        marker_color='lightgreen'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Country Code Distribution Before and After Cleaning',\n",
    "        xaxis_title='Country Code',\n",
    "        yaxis_title='Count',\n",
    "        barmode='group'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "plot_country_distribution(original_df, cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hashtag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_hashtags(df, column='hashtags'):\n",
    "    # Split hashtags and create a list of all hashtags\n",
    "    all_hashtags = [tag for tags in df[column].dropna() \n",
    "                    for tag in str(tags).split()]\n",
    "    \n",
    "    # Count unique hashtags\n",
    "    unique_hashtags = len(set(all_hashtags))\n",
    "    \n",
    "    # Get top hashtags\n",
    "    top_hashtags = pd.Series(all_hashtags).value_counts().head(10)\n",
    "    \n",
    "    # Create word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white')\n",
    "    wordcloud.generate(' '.join(all_hashtags))\n",
    "    \n",
    "    # Plotting\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Plot top hashtags\n",
    "    top_hashtags.plot(kind='barh', ax=ax1)\n",
    "    ax1.set_title('Top 10 Hashtags')\n",
    "    \n",
    "    # Plot word cloud\n",
    "    ax2.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Hashtag Word Cloud')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Total Hashtags': len(all_hashtags),\n",
    "        'Unique Hashtags': unique_hashtags,\n",
    "        'Average Hashtags per Record': len(all_hashtags) / len(df),\n",
    "        'Records with Hashtags (%)': (df[column].notna().sum() / len(df) * 100).round(2)\n",
    "    })\n",
    "\n",
    "print(\"Original Dataset Hashtag Analysis:\")\n",
    "original_hashtag_stats = analyze_hashtags(original_df)\n",
    "print(original_hashtag_stats)\n",
    "\n",
    "print(\"\\nCleaned Dataset Hashtag Analysis:\")\n",
    "cleaned_hashtag_stats = analyze_hashtags(cleaned_df)\n",
    "print(cleaned_hashtag_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Development Status Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_development_status(original_df, cleaned_df):\n",
    "    # Create comparison DataFrame\n",
    "    comparison = pd.DataFrame({\n",
    "        'Original': original_df['development_status'].value_counts(normalize=True) * 100,\n",
    "        'Cleaned': cleaned_df['development_status'].value_counts(normalize=True) * 100\n",
    "    }).round(2)\n",
    "    \n",
    "    # Calculate changes\n",
    "    comparison['Change (%)'] = (comparison['Cleaned'] - comparison['Original']).round(2)\n",
    "    \n",
    "    # Plotting\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Pie charts\n",
    "    original_df['development_status'].value_counts().plot(\n",
    "        kind='pie', autopct='%1.1f%%', ax=ax1, title='Original Distribution')\n",
    "    cleaned_df['development_status'].value_counts().plot(\n",
    "        kind='pie', autopct='%1.1f%%', ax=ax2, title='Cleaned Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "development_status_comparison = analyze_development_status(original_df, cleaned_df)\n",
    "development_status_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
